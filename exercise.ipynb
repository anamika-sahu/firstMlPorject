{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afdd69cf",
   "metadata": {},
   "source": [
    "# McKinsey Training - Constructing a Workflow in MLRun\n",
    "This exercise will use the provided [Palmer Archipelago (Antarctica) penguin dataset](https://www.kaggle.com/datasets/parulpandey/palmer-archipelago-antarctica-penguin-data) and Python files to create a training and deployment pipeline. The pipeline will have 3 steps (data processing, model training, model deployment).\n",
    "\n",
    "The three source code components are written for you, however it will be your job to use MLRun to containerize and orchestrate the components together into a larger pipeline (relevant links to documentation will be provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d9a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948ee304",
   "metadata": {},
   "source": [
    "## 1. Create an MLRun Project\n",
    "Use [mlrun.get_or_create_project](https://docs.mlrun.org/en/latest/api/mlrun.projects.html#mlrun.projects.get_or_create_project) to create a project with the name \"penguin-classification\" in the current directory. Ensure that `user_project=True` so that the project is unique to you.\n",
    "\n",
    "Relevant docs: [Get a project from DB or create it](https://docs.mlrun.org/en/latest/projects/create-project.html#get-or-create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ccf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = mlrun.get_or_create_project(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f0715",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0321b4",
   "metadata": {},
   "source": [
    "## 2. Register the Source Code as MLRun Functions\n",
    "\n",
    "Use [project.set_function](https://docs.mlrun.org/en/latest/api/mlrun.projects.html#mlrun.projects.MlrunProject.set_function) to register the following 3 provided Python files as MLRun functions within the project:\n",
    "- `data`: Located in `src/data.py`, Register as `job`, Look at source code for name of `handler`\n",
    "- `train`: Located in `src/train.py`, Register as `job`, Look at source code for name of `handler`\n",
    "- `serving`: Located in `src/serve.py`, Register as `serving`\n",
    "\n",
    "Relevant docs: [Create and use functions](https://docs.mlrun.org/en/latest/runtimes/create-and-use-functions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5fb1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_function(name=\"data\", ...)\n",
    "project.set_function(name=\"train\", ...)\n",
    "project.set_function(name=\"serving\", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e685673",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65d50a2",
   "metadata": {},
   "source": [
    "## 3. Write a Batch Workflow Using the 3 Functions\n",
    "\n",
    "The batch workflow should have 3 steps and use each of the previously registered MLRun functions. The steps will be process data, train model, deploy model. A skeleton of the pipeline has been provided - you can edit the cell directly in the notebook it will write to the corresponding `src/pipeline.py` file.\n",
    "\n",
    "In general for each step, you will:\n",
    "- Retrieve the function from the project via [project.get_function()](https://docs.mlrun.org/en/latest/api/mlrun.projects.html?highlight=get_function#mlrun.projects.MlrunProject.get_function)\n",
    "- Optional: Apply customizations to the function (e.g. requests/limits, node selection, volume mounts, etc.)\n",
    "- Execute the function via [project.run_function](https://docs.mlrun.org/en/latest/api/mlrun.projects.html?highlight=run_function#mlrun.projects.MlrunProject.run_function) for batch runtimes or [project.deploy_function](https://docs.mlrun.org/en/latest/api/mlrun.projects.html?highlight=deploy_function#mlrun.projects.MlrunProject.deploy_function) for real-time runtimes\n",
    "\n",
    "Relevant docs: [Create and use functions](https://docs.mlrun.org/en/latest/runtimes/create-and-use-functions.html), [Build and run workflows/pipelines](https://docs.mlrun.org/en/latest/projects/build-run-workflows-pipelines.html), [Managing job resources](https://docs.mlrun.org/en/latest/runtimes/configuring-job-resources.html), [Inputs vs params](https://docs.mlrun.org/en/latest/concepts/submitting-tasks-jobs-to-functions.html#submit-tasks-jobs-using-run-function), [Adding models to a serving function](https://docs.mlrun.org/en/latest/api/mlrun.runtimes.html#mlrun.runtimes.ServingRuntime.add_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d4714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/pipeline.py\n",
    "from kfp import dsl\n",
    "import mlrun\n",
    "import nuclio\n",
    "\n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(\n",
    "    name=\"penguin-classification-pipeline\",\n",
    "    description=\"Example of batch pipeline for palmer penguin dataset\"\n",
    ")\n",
    "def pipeline(dataset: str, label_column: str = \"species\"):\n",
    "    \n",
    "    # Get current project\n",
    "    project = mlrun.get_current_project()\n",
    "    \n",
    "    # Process data\n",
    "    data_fn = project.get_function(\"data\").apply(mlrun.mount_v3io())\n",
    "    data_run = project.run_function(\n",
    "        function=data_fn,\n",
    "        inputs={},\n",
    "        params={},\n",
    "        outputs=[]\n",
    "    )\n",
    "    \n",
    "    # Train a model\n",
    "    train_fn = project.get_function(\"train\")\n",
    "    train_run = project.run_function(\n",
    "        function=train_fn,\n",
    "        inputs={},\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    # Deploy the model as a serverless function\n",
    "    serving_fn = project.get_function(\"serving\")\n",
    "    serving_fn.add_model(...)\n",
    "    deploy_run = mlrun.deploy_function(function=serving_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b712471",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472291d",
   "metadata": {},
   "source": [
    "## 4. Register Batch Workflow in Project and Save\n",
    "\n",
    "Next, register the newly written batch workflow into the project via [project.set_workflow()](https://docs.mlrun.org/en/latest/api/mlrun.projects.html?highlight=set_workflow#mlrun.projects.MlrunProject.set_workflow) and save.\n",
    "\n",
    "Relevant docs: [Running a multi-stage workflow](https://docs.mlrun.org/en/latest/concepts/workflow-overview.html), [Projects and automated ML pipeline](https://docs.mlrun.org/en/latest/tutorial/04-pipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aea913",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_workflow(...)\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae99e2f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7056009a",
   "metadata": {},
   "source": [
    "## 5. Execute the Workflow via the MLRun Project\n",
    "\n",
    "Start a run of the newly registered workflow using [project.run()](https://docs.mlrun.org/en/latest/api/mlrun.projects.html?highlight=MlrunProject.run#mlrun.projects.MlrunProject.run). Pass a dictionary of arguments that includes the key `dataset` and the value of the path to the desired penguin dataset.\n",
    "\n",
    "Relevant docs: [Running a multi-stage workflow](https://docs.mlrun.org/en/latest/concepts/workflow-overview.html), [Projects and automated ML pipeline](https://docs.mlrun.org/en/latest/tutorial/04-pipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf5a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = f\"{os.getcwd()}/data/palmer_penguins.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.run(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc15903f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f263cfd1",
   "metadata": {},
   "source": [
    "## 6. Send a Test HTTP Request to the Newly Deployed Model\n",
    "\n",
    "Finally, use the provided model input to make a test HTTP request to the newly deployed model. You can retrieve the serving function via [project.get_function()](https://docs.mlrun.org/en/latest/api/mlrun.projects.html?highlight=get_function#mlrun.projects.MlrunProject.get_function) and invoke it via [serve_fn.invoke()](https://docs.mlrun.org/en/latest/api/mlrun.runtimes.html?highlight=invoke#mlrun.runtimes.RemoteRuntime.invoke)\n",
    "\n",
    "Relevant docs: [Serving pre-trained ML/DL models](https://docs.mlrun.org/en/latest/tutorial/03-model-serving.html#deploy-the-serving-function), [Quick start tutorial](https://docs.mlrun.org/en/latest/tutorial/01-mlrun-basics.html#build-test-and-deploy-the-model-serving-functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_INPUT = {\n",
    "    'inputs': [\n",
    "        [0.0, 1.0, 0.0, 1.0, 0.0, 39.5, 16.7, 178.0, 3250.0],\n",
    "        [1.0, 0.0, 0.0, 1.0, 0.0, 46.9, 14.6, 222.0, 4875.0],\n",
    "        [0.0, 0.0, 1.0, 0.0, 1.0, 42.1, 19.1, 195.0, 4000.0],\n",
    "        [0.0, 1.0, 0.0, 1.0, 0.0, 49.8, 17.3, 198.0, 3675.0],\n",
    "        [1.0, 0.0, 0.0, 0.0, 1.0, 41.1, 18.2, 192.0, 4050.0]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve_fn = project.get_function(\"serving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b52c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve_fn.invoke(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37556c04",
   "metadata": {},
   "source": [
    "## 7. Bonus: Apply Specific Resource Request/Limits to Training Job\n",
    "\n",
    "As an bonus exercise, modify the batch workflow to apply specific resource requests/limits to the training job. This will take place between retrieving the function from the project and executing the function itself.\n",
    "\n",
    "Relevant docs: [Managing job resources](https://docs.mlrun.org/en/latest/runtimes/configuring-job-resources.html), [Customizing functions](https://docs.mlrun.org/en/latest/runtimes/create-and-use-functions.html#customizing-functions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
